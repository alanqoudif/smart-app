## üéØ Database Schema - Improvements & Recommendations

### Executive Summary

Your current database schema is **functionally complete** for the restaurant management use case. However, this document identifies **potential improvements** and **missing components** that would enhance the system for production deployment at scale.

---

## üî¥ Critical Missing Components

### 1. Authentication System Integration

**Current State:** Schema has `owner_password_hash` and `passcode_hash` but no integration with Supabase Auth

**Issue:**
- Manual password management is error-prone
- No built-in session management
- Missing features: email verification, password reset, OAuth

**Recommendation:**
```sql
-- Option A: Link to Supabase Auth
create table if not exists public.user_profiles (
  id uuid primary key references auth.users (id) on delete cascade,
  restaurant_id uuid references public.restaurants (id) on delete cascade,
  staff_id uuid references public.staff_accounts (id) on delete cascade,
  created_at timestamptz default now()
);

-- Option B: Add auth metadata to staff_accounts
alter table public.staff_accounts 
  add column auth_user_id uuid references auth.users (id) on delete set null;
```

**Benefit:**
- Leverage Supabase Auth features
- Better security (2FA, magic links, social login)
- Automatic session management

---

### 2. Real-Time Subscriptions Strategy

**Current State:** No optimization for Supabase Realtime subscriptions

**Issue:**
- Kitchen Display System needs real-time order updates
- Potential performance issues with large datasets

**Recommendation:**
```sql
-- Add publication for realtime
create publication kitchen_updates for table orders 
  where (status in ('new', 'preparing', 'ready'));

-- Add replica identity for realtime updates
alter table orders replica identity full;
alter table order_items replica identity full;

-- Client-side subscription (TypeScript)
const subscription = supabase
  .channel('kitchen-orders')
  .on('postgres_changes', {
    event: '*',
    schema: 'public',
    table: 'orders',
    filter: `restaurant_id=eq.${restaurantId}`
  }, (payload) => {
    console.log('Order changed:', payload);
  })
  .subscribe();
```

**Benefit:**
- Instant updates to kitchen display
- Reduced polling requests
- Better user experience

---

### 3. Soft Deletes for Critical Data

**Current State:** Hard deletes via `on delete cascade`

**Issue:**
- Permanently deleted data cannot be recovered
- Compliance issues (GDPR requires audit trails)
- Cannot analyze deleted records

**Recommendation:**
```sql
-- Add soft delete columns
alter table orders add column deleted_at timestamptz;
alter table customers add column deleted_at timestamptz;
alter table menu_items add column deleted_at timestamptz;

-- Create filtered views
create view active_orders as
  select * from orders where deleted_at is null;

-- Update RLS policies to exclude deleted
create policy "Orders: View active only"
  on orders for select
  using (restaurant_id = current_restaurant_id() and deleted_at is null);

-- Soft delete function
create or replace function soft_delete(
  table_name text,
  record_id uuid
) returns void as $$
begin
  execute format('UPDATE %I SET deleted_at = now() WHERE id = $1', table_name)
  using record_id;
end;
$$ language plpgsql security definer;
```

**Benefit:**
- Data recovery possible
- Better analytics (track deletion patterns)
- Compliance-friendly

---

### 4. Order Versioning / History

**Current State:** No order edit history

**Issue:**
- Cannot track order changes (e.g., items added/removed)
- Disputes are hard to resolve
- No "before" snapshot if order modified

**Recommendation:**
```sql
create table order_history (
  id uuid primary key default uuid_generate_v4(),
  order_id uuid not null references orders (id) on delete cascade,
  staff_id uuid references staff_accounts (id) on delete set null,
  change_type text not null check (change_type in ('created', 'item_added', 'item_removed', 'status_changed', 'cancelled')),
  snapshot jsonb not null, -- Full order state at this point
  created_at timestamptz default now()
);

create index idx_order_history_order on order_history (order_id, created_at desc);

-- Trigger to auto-create history entry
create or replace function track_order_changes()
returns trigger as $$
begin
  insert into order_history (order_id, change_type, snapshot)
  values (
    coalesce(new.id, old.id),
    case TG_OP
      when 'INSERT' then 'created'
      when 'DELETE' then 'cancelled'
      when 'UPDATE' then 
        case when new.status != old.status then 'status_changed' else 'modified' end
    end,
    row_to_json(coalesce(new, old))
  );
  return coalesce(new, old);
end;
$$ language plpgsql;

create trigger track_order_changes_trigger
  after insert or update or delete on orders
  for each row execute function track_order_changes();
```

**Benefit:**
- Full audit trail
- Dispute resolution
- Analytics on order modifications

---

## üü° Performance Optimizations

### 5. Materialized Views for Heavy Analytics

**Current State:** Views recalculate on every query

**Issue:**
- Dashboard queries may become slow with large datasets
- Repeated calculations waste resources

**Recommendation:**
```sql
-- Create materialized view for daily dashboard
create materialized view daily_dashboard_cache as
select
  restaurant_id,
  date_trunc('day', created_at) as date,
  count(*) as total_orders,
  sum(total) filter (where status != 'cancelled') as revenue,
  avg(total) filter (where status != 'cancelled') as avg_order_value,
  count(distinct customer_id) as unique_customers
from orders
group by restaurant_id, date_trunc('day', created_at);

create unique index on daily_dashboard_cache (restaurant_id, date);

-- Refresh daily at midnight
-- (Add to cron job or pg_cron extension)
refresh materialized view concurrently daily_dashboard_cache;
```

**Benefit:**
- Instant dashboard load times
- Reduced database load
- Scalable to millions of orders

---

### 6. Partitioning for Orders Table

**Current State:** Single large orders table

**Issue:**
- Queries slow down as table grows beyond 1M rows
- Index bloat over time
- Inefficient archival

**Recommendation:**
```sql
-- Convert to partitioned table (PostgreSQL 11+)
-- NOTE: Requires recreating table - plan carefully!

create table orders_new (
  id uuid default uuid_generate_v4(),
  restaurant_id uuid not null,
  -- ... all other fields
  created_at timestamptz default now(),
  primary key (id, created_at)
) partition by range (created_at);

-- Create monthly partitions
create table orders_2024_01 partition of orders_new
  for values from ('2024-01-01') to ('2024-02-01');

create table orders_2024_02 partition of orders_new
  for values from ('2024-02-01') to ('2024-03-01');

-- Auto-create partitions (requires pg_cron or external scheduler)
create or replace function create_next_partition() returns void as $$
declare
  next_month date := date_trunc('month', now() + interval '1 month');
begin
  execute format(
    'CREATE TABLE IF NOT EXISTS orders_%s PARTITION OF orders FOR VALUES FROM (%L) TO (%L)',
    to_char(next_month, 'YYYY_MM'),
    next_month,
    next_month + interval '1 month'
  );
end;
$$ language plpgsql;
```

**When to Implement:**
- Orders table exceeds 1 million rows
- Queries on recent orders are slow
- Historical data needs archival

**Benefit:**
- 10-100x faster queries on recent data
- Easy archival (detach old partitions)
- Better vacuum performance

---

### 7. Connection Pooling Configuration

**Current State:** Direct connections to database

**Issue:**
- Supabase has connection limits (varies by plan)
- Serverless functions may exhaust connections
- Connection overhead on each request

**Recommendation:**
```javascript
// Use Supabase built-in pooler or external like PgBouncer

// Option 1: Supabase Pooler (recommended)
const supabase = createClient(
  process.env.SUPABASE_URL,
  process.env.SUPABASE_ANON_KEY,
  {
    db: {
      schema: 'public',
    },
    auth: {
      persistSession: false, // For serverless
    },
    global: {
      headers: {
        'X-Connection-Mode': 'session', // or 'transaction'
      },
    },
  }
);

// Option 2: External PgBouncer
// pool_mode = transaction (best for serverless)
// max_client_conn = 10000
// default_pool_size = 20
```

**Benefit:**
- Scales to 10K+ concurrent users
- Prevents connection exhaustion
- Lower latency

---

## üü¢ Feature Enhancements

### 8. Multi-Currency Support

**Current State:** Single currency per restaurant

**Issue:**
- Cannot expand to international markets
- Exchange rates not handled

**Recommendation:**
```sql
-- Add currency to relevant tables
alter table orders add column currency_code text default 'SAR';
alter table orders add column exchange_rate numeric(10, 6) default 1.0;

-- Create currency table
create table currencies (
  code text primary key, -- ISO 4217 (USD, SAR, AED)
  name text not null,
  symbol text not null,
  decimal_places smallint default 2,
  is_active boolean default true
);

insert into currencies (code, name, symbol) values
  ('SAR', 'Saudi Riyal', 'ÿ±.ÿ≥'),
  ('AED', 'UAE Dirham', 'ÿØ.ÿ•'),
  ('USD', 'US Dollar', '$'),
  ('EUR', 'Euro', '‚Ç¨');

-- Function to convert amounts
create or replace function convert_currency(
  amount numeric,
  from_currency text,
  to_currency text
) returns numeric as $$
  -- Implement exchange rate logic here
  -- Could integrate with external API
$$ language plpgsql;
```

**Benefit:**
- International expansion
- Multi-currency reporting
- Accurate financial records

---

### 9. Discount & Promotion System

**Current State:** Single `discount` field on orders

**Issue:**
- No tracking of *why* discount applied
- Cannot create reusable promotions
- No expiration dates

**Recommendation:**
```sql
create table promotions (
  id uuid primary key default uuid_generate_v4(),
  restaurant_id uuid not null references restaurants (id) on delete cascade,
  code text not null, -- e.g., "SUMMER20"
  name text not null,
  discount_type text not null check (discount_type in ('percentage', 'fixed_amount', 'buy_x_get_y')),
  discount_value numeric(10, 2) not null,
  min_order_amount numeric(10, 2),
  max_discount_amount numeric(10, 2),
  valid_from timestamptz not null,
  valid_until timestamptz not null,
  usage_limit integer,
  usage_count integer default 0,
  is_active boolean default true,
  applicable_to text[] default '{}'::text[], -- menu item IDs or categories
  unique(restaurant_id, code)
);

create table order_promotions (
  id uuid primary key default uuid_generate_v4(),
  order_id uuid not null references orders (id) on delete cascade,
  promotion_id uuid not null references promotions (id) on delete restrict,
  discount_applied numeric(10, 2) not null,
  created_at timestamptz default now()
);

-- Function to apply promotion
create or replace function apply_promotion(
  p_order_id uuid,
  p_promo_code text
) returns jsonb as $$
  -- Validation and calculation logic
$$ language plpgsql;
```

**Benefit:**
- Marketing campaigns
- Loyalty programs
- A/B testing discounts
- Fraud prevention (usage limits)

---

### 10. Delivery Integration

**Current State:** Basic delivery fields

**Issue:**
- No driver assignment
- No delivery tracking
- No delivery partner integration

**Recommendation:**
```sql
create table delivery_drivers (
  id uuid primary key default uuid_generate_v4(),
  restaurant_id uuid not null references restaurants (id) on delete cascade,
  name text not null,
  phone text not null,
  vehicle_type text,
  status text default 'offline' check (status in ('offline', 'available', 'busy', 'delivering')),
  current_order_id uuid references orders (id) on delete set null,
  created_at timestamptz default now()
);

create table delivery_tracking (
  id uuid primary key default uuid_generate_v4(),
  order_id uuid not null references orders (id) on delete cascade,
  driver_id uuid references delivery_drivers (id) on delete set null,
  status text not null check (status in ('assigned', 'picked_up', 'in_transit', 'delivered', 'failed')),
  latitude numeric(10, 7),
  longitude numeric(10, 7),
  estimated_delivery_time timestamptz,
  actual_delivery_time timestamptz,
  created_at timestamptz default now()
);

-- Trigger to notify driver on order ready
create or replace function assign_delivery_driver()
returns trigger as $$
declare
  v_driver_id uuid;
begin
  if new.status = 'ready' and new.fulfillment_type = 'delivery' then
    -- Find available driver
    select id into v_driver_id
    from delivery_drivers
    where restaurant_id = new.restaurant_id
      and status = 'available'
    order by random() -- or by proximity in production
    limit 1;
    
    if v_driver_id is not null then
      -- Assign driver
      insert into delivery_tracking (order_id, driver_id, status)
      values (new.id, v_driver_id, 'assigned');
      
      update delivery_drivers
      set status = 'busy', current_order_id = new.id
      where id = v_driver_id;
    end if;
  end if;
  return new;
end;
$$ language plpgsql;

create trigger assign_delivery_driver_trigger
  after update on orders
  for each row execute function assign_delivery_driver();
```

**Benefit:**
- Driver management
- Real-time tracking
- Better customer experience
- Integration with third-party delivery

---

### 11. Reservation System

**Current State:** Tables exist but no reservation logic

**Issue:**
- Cannot book tables in advance
- No waitlist management
- No capacity planning

**Recommendation:**
```sql
create table reservations (
  id uuid primary key default uuid_generate_v4(),
  restaurant_id uuid not null references restaurants (id) on delete cascade,
  customer_id uuid references customers (id) on delete set null,
  table_id uuid references tables (id) on delete set null,
  guest_name text not null,
  guest_phone text not null,
  guest_count integer not null check (guest_count > 0),
  reservation_time timestamptz not null,
  duration_minutes integer default 90,
  status text default 'pending' check (status in ('pending', 'confirmed', 'seated', 'completed', 'cancelled', 'no_show')),
  special_requests text,
  created_at timestamptz default now(),
  check (reservation_time > now()) -- Cannot reserve in past
);

create index idx_reservations_time on reservations (restaurant_id, reservation_time);
create index idx_reservations_status on reservations (restaurant_id, status) where status in ('pending', 'confirmed');

-- Function to check table availability
create or replace function check_table_availability(
  p_restaurant_id uuid,
  p_table_id uuid,
  p_time timestamptz,
  p_duration integer default 90
) returns boolean as $$
declare
  v_conflicts integer;
begin
  select count(*) into v_conflicts
  from reservations
  where table_id = p_table_id
    and status in ('confirmed', 'seated')
    and reservation_time < p_time + (p_duration || ' minutes')::interval
    and reservation_time + (duration_minutes || ' minutes')::interval > p_time;
  
  return v_conflicts = 0;
end;
$$ language plpgsql;
```

**Benefit:**
- Reduce wait times
- Better capacity utilization
- Improved customer satisfaction
- Revenue optimization

---

### 12. Reviews & Ratings

**Current State:** No feedback mechanism

**Issue:**
- Cannot collect customer feedback
- No quality metrics
- Missing improvement insights

**Recommendation:**
```sql
create table reviews (
  id uuid primary key default uuid_generate_v4(),
  restaurant_id uuid not null references restaurants (id) on delete cascade,
  order_id uuid references orders (id) on delete set null,
  customer_id uuid references customers (id) on delete set null,
  rating integer not null check (rating between 1 and 5),
  food_quality integer check (food_quality between 1 and 5),
  service_quality integer check (service_quality between 1 and 5),
  cleanliness integer check (cleanliness between 1 and 5),
  comment text,
  is_public boolean default true,
  staff_response text,
  created_at timestamptz default now()
);

create index idx_reviews_restaurant on reviews (restaurant_id, created_at desc);
create index idx_reviews_rating on reviews (restaurant_id, rating);

-- Aggregate ratings view
create view restaurant_ratings as
select
  restaurant_id,
  count(*) as review_count,
  avg(rating) as avg_rating,
  avg(food_quality) as avg_food_quality,
  avg(service_quality) as avg_service_quality,
  avg(cleanliness) as avg_cleanliness,
  count(*) filter (where rating = 5) as five_star_count,
  count(*) filter (where rating = 1) as one_star_count
from reviews
group by restaurant_id;
```

**Benefit:**
- Customer insights
- Public reputation
- Staff training opportunities
- Service improvement

---

## üîµ Operational Improvements

### 13. Database Backup Strategy

**Recommendation:**
```bash
# Automated daily backups with retention
#!/bin/bash
BACKUP_DIR="/backups/postgres"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
DB_NAME="smart_restaurant"

# Full backup
pg_dump -Fc $DB_NAME > "$BACKUP_DIR/full_$TIMESTAMP.dump"

# Incremental backup using WAL archiving
# (Configure in postgresql.conf)
# archive_mode = on
# archive_command = 'cp %p /backups/wal/%f'

# Retention: Keep last 7 days, monthly archives
find $BACKUP_DIR -name "full_*.dump" -mtime +7 -delete
```

**Point-in-Time Recovery Setup:**
```sql
-- Enable WAL archiving
ALTER SYSTEM SET wal_level = replica;
ALTER SYSTEM SET archive_mode = on;
ALTER SYSTEM SET archive_command = 'test ! -f /backups/wal/%f && cp %p /backups/wal/%f';

-- Restart required
SELECT pg_reload_conf();
```

---

### 14. Monitoring & Alerting

**Recommendation:**
```sql
-- Create monitoring views
create view slow_queries as
select
  query,
  calls,
  total_exec_time,
  mean_exec_time,
  max_exec_time
from pg_stat_statements
where mean_exec_time > 100 -- slower than 100ms
order by mean_exec_time desc;

-- Table bloat detection
create view table_bloat as
select
  schemaname,
  tablename,
  pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size,
  n_live_tup as live_rows,
  n_dead_tup as dead_rows,
  round((n_dead_tup::numeric / nullif(n_live_tup, 0)) * 100, 2) as bloat_percentage
from pg_stat_user_tables
where n_dead_tup > 1000
order by n_dead_tup desc;

-- Active connections
create view connection_stats as
select
  datname,
  count(*) as connections,
  count(*) filter (where state = 'active') as active,
  count(*) filter (where state = 'idle') as idle,
  count(*) filter (where state = 'idle in transaction') as idle_in_transaction
from pg_stat_activity
group by datname;
```

**Alerting Rules:**
- Connection count > 80% of max
- Slow query mean time > 500ms
- Table bloat > 20%
- Failed transactions > 1% of total
- Disk space < 20% remaining

---

### 15. Disaster Recovery Plan

**Components:**
1. **Automated backups** (daily full + continuous WAL)
2. **Replication** (hot standby for failover)
3. **Geographic distribution** (multi-region for high availability)
4. **Restore testing** (monthly dry runs)
5. **Documentation** (runbooks for common failures)

**RTO/RPO Targets:**
- Recovery Time Objective (RTO): < 15 minutes
- Recovery Point Objective (RPO): < 5 minutes (data loss window)

---

## üìä Priority Matrix

### Immediate (Next Sprint)
1. ‚úÖ Authentication integration with Supabase Auth
2. ‚úÖ Real-time subscriptions setup
3. ‚úÖ Soft deletes implementation

### Short-Term (1-3 Months)
4. ‚úÖ Order history/versioning
5. ‚úÖ Materialized views for dashboard
6. ‚úÖ Promotion system
7. ‚úÖ Reviews & ratings

### Medium-Term (3-6 Months)
8. ‚úÖ Delivery tracking
9. ‚úÖ Reservation system
10. ‚úÖ Multi-currency support

### Long-Term (6-12 Months)
11. ‚úÖ Table partitioning (when orders > 1M)
12. ‚úÖ Advanced analytics (ML models)
13. ‚úÖ Multi-location management for chains

---

## üéì Additional Considerations

### Data Privacy & Compliance

**GDPR/CCPA Compliance:**
```sql
-- Add data retention policies
create table data_retention_policies (
  table_name text primary key,
  retention_days integer not null,
  anonymize_after_days integer
);

-- Data export function (GDPR right to data portability)
create or replace function export_customer_data(p_customer_id uuid)
returns jsonb as $$
  select jsonb_build_object(
    'customer', (select row_to_json(c) from customers c where id = p_customer_id),
    'orders', (select jsonb_agg(row_to_json(o)) from orders o where customer_id = p_customer_id),
    'reviews', (select jsonb_agg(row_to_json(r)) from reviews r where customer_id = p_customer_id)
  );
$$ language sql;

-- Anonymization function
create or replace function anonymize_customer(p_customer_id uuid)
returns void as $$
  update customers
  set
    full_name = 'Deleted User',
    phone = 'DELETED',
    email = null,
    notes = null
  where id = p_customer_id;
$$ language sql;
```

---

## üìù Summary

Your database schema is **solid** and production-ready for initial launch. The recommendations above are **progressive enhancements** to add as your application scales and requirements evolve.

**Prioritize based on:**
1. **User Pain Points** - What's blocking users?
2. **Business Goals** - What drives revenue?
3. **Technical Debt** - What prevents scaling?

**Start with:**
- Authentication integration (security)
- Real-time subscriptions (UX)
- Soft deletes (compliance)

**Then expand to:**
- Promotions (marketing)
- Reviews (reputation)
- Delivery tracking (operations)

---

**Document Version:** 1.0  
**Last Updated:** December 2024  
**Status:** Advisory üìã

